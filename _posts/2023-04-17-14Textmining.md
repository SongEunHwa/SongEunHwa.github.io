---
layout: single
title:  "14.Sentiment Analysis 실습"
categories: TextMining
tag: [python,Jupyter Notebook,TextMining]
toc: true
toc_sticky: true
author_profile: false #옆에 정보 끄기
sidebar: 
    nav: "docs"
typora-root-url: ../
---

<div class="notice--info">
<h4>💡목표</h4>
<ul>
    <li>감성분석의 종류에 대해 이해하기.</li>
    <li>어휘사전에 의한 감성분석의 종류 알아보기.</li>
    <li>머신러닝/딥러닝에 대한 감성분석 알아보기.</li>
</ul>
</div>
#### 14강. Sentiment Analysis 실습

##### 01. 패키지 및 데이터파일 불러오기

```python
import pandas as pd                         #데이터 구조
from nltk.tokenize import word_tokenize     #토큰화
from nltk.corpus import stopwords           #불용어
from nltk.stem import PorterStemmer         #어간추출
import re                                   #정규표현식

file=pd.read_csv('wos_ai_.csv', encoding='utf-8')
```

데이터 전처리에 필요한 패키지와 wos_at_.csv 데이터의 ABSTRACK 열만 추출해서 불러들입니다.

```python
file=pd.DataFrame(file)
file.info()
```

![image-20230417050641519](/images/image-20230417050641519.png)

file의 데이터구조를 살펴보면, 년도(YEAR), 제목(TITLE), 작가(AUTHOR), 초록(ABSTRACT)를 확인할 수 있습니다.

여기서 저희는 ABSTRACT 데이터로 감정분석을 하게 될텐데, 연도별로도 파악해보도록 하겠습니다.

##### 02. 초록/연도 구분 및 데이터셋 준비

```python
data = file.ABSTRACT
year = file.YEAR
```

```python
doc_set = []  #문장을 저장할 공간
words = []    #단어들을 저장할 공간
wordsForSentiment = [] #감정분석을 위한 공간
```

ABSTRACT에 대한 데이터를 data 변수에 넣어주고 YEAR에 대한 데이터를 year 변수에 각각 넣어 주었습니다.

전처리 과정 중에 필요한 공간을 doc_set 문장구조로 넣을 공간과 words 단어로 넣을 공간을 지정해 줍니다. 그리고 감정분석을 위해 별도 공간도 wordsForSentiment 로 만들어주겠습니다.

##### 03. 데이터 전처리 (영어만 남기기)

11강에서 진행했던 데이터전처리 과정을 진행해줍니다.

```python
# "_" 구분자를 공백으로 바꿔주기
for doc in data:
    if type(doc)!=float:
        doc_set.append(doc.replace("_", " "))

# 불용어처리를 위해 불용어사전을 stopWords에 저장
stopWords=set(stopwords.words("english"))

# 어간추출을 위한 명령문을 따로 저장해두기
stemmer=PorterStemmer()

# 전처리 과정
for doc in doc_set:
    noPunctionWords = re.sub(r"[^a-zA-Z]+", " ", str(doc)) #알파벳을 제외하고 공백처리
    tokenizedwords = word_tokenize(noPunctionWords.lower()) #토큰화
    stoppedwords = [w for w in tokenizedwords if w not in stopWords] #불용어처리
    stemmedwords = [stemmer.stem(w) for w in stoppedwords] #어간추출
    words.append(" ".join(stemmedwords)) #전처리된 단어를 문장으로 다시 이어준다.
    wordsForSentiment.append(stoppedwords) #이어진 문장을 하나의 문서로 만들어줌

wordsForSentiment
```

자세한 전처리 과정에 대한 설명은 링크를 통해 확인해주세요.

[방법1) 정규식을 이용해 알파벳만 남기기](https://songeunhwa.github.io/textmining/11Textmining/#%EB%B0%A9%EB%B2%951-%EC%A0%95%EA%B7%9C%EC%8B%9D%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%B4-%EC%95%8C%ED%8C%8C%EB%B2%B3%EB%A7%8C-%EB%82%A8%EA%B8%B0%EA%B8%B0)

전처리가 끝난 wordsForSentiment의 변수의 형태는 아래 사진 형태와 같습니다.

![image-20230417052524590](/images/image-20230417052524590.png)

여기서 명심해야할 부분은 내가 가진 감정분석 사전이 전처리가 된 형태라면 위와 동일하게 진행하면 되지만 전처리가 되지 않은 형태의 사전이라면 어간을 추출하지 않은 stoppedwords의 변수를 사용해야 한다.

이는 **연구자가 사용하는 감정분석 사전에 따라서 조정**해야할 필요가 있다. 여기에선 전처리가 된 사전을 사용할 것이기에 위와 같은 전처리를 진행하였다.

이제 사전을 불러오자.

```python
posFile=pd.read_csv("positive-words.txt", encoding='utf-8')
negFile=pd.read_csv("negative-words.txt", encoding='utf-8')
```

여기서 posFile의 데이터형태는 type(posFile)로 살펴보면 데이터프레임 형태인데 우리가 만든 wordsForSentiment 변수의 데이터형태는 list 형태이기 때문에 같은 형태로 만들어 줘야한다.

```python
posWords=set(posFile['POSITIVE'].tolist())
negWords=set(negFile['NEGATIVE'].tolist())
```

.tolist() 함수를 사용해서 데이터프레임형태에서 리스트형태로 바꿔준 후에 set에 넣어주자. 여기서 'POSTIVE'와 'NEGATIVE'로 지정해주는 이유는 아래 사진을 살펴보면

![image-20230417055630762](/images/image-20230417055630762.png)

열 이름이 각자 'PSTIVE'와 'NEGATIVE'로 되어있기 때문에 해당 열의 데이터만 추출해서 리스트로 만들고 만들어진 리스트를 set에 넣어놓겠다는 뜻이다.
